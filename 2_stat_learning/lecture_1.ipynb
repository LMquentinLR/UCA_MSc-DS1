{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Learning - lecture 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal**\n",
    "\n",
    "1. understand the maths behind the algorithms that you learn\n",
    "2. learn about theoretical guarantees on existing algorithms\n",
    "\n",
    "**Requirements**\n",
    "\n",
    "- Elementary real analysis: functions of a real variable (Lipschitz continuity)\n",
    "- Calculus\n",
    "- Basic Probability Theory\n",
    "- Limit Theorems\n",
    "- Linear Algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Statistical Learning\n",
    "\n",
    "Four ingredients made statistical learning a viable paradigm:\n",
    "\n",
    "- data to feed to the models\n",
    "- computing power\n",
    "- complexity of the model\n",
    "- efficient algorithms to train the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Concept\n",
    "\n",
    "An **input space** is some measurable space $\\mathcal{X}$ that contains all the objects that we want to label. It is also called *domain* or *domain set*.\n",
    "\n",
    "Elements $x\\in \\mathcal{X}$ are usuall described as *vectors*. The coordinates of a vector is called a *feature*.\n",
    "\n",
    "<u>Example:</u> RGB images -> 3 8-bits channels\n",
    "\n",
    "<u>Remark:</u> $\\mathcal{X}$ can be very high-dimensional in modern applications (a RGB 299x299px image is 268,203 dimensions).\n",
    "\n",
    "A **label set**: labels belongs to a set $\\mathcal{Y}$. We restrict ourselves to $\\mathcal{Y}=\\{0,1\\}$ for the time being but can be much larger in modern applications\n",
    "\n",
    "**Training data** $\\mathcal{S} = ((x_1,y_1), ..., (x_n,y_n))$, a finite sequence of points of $\\mathcal{X}\\times\\mathcal{Y}$. also called a *training set*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis class\n",
    "\n",
    "An **hypothesis** $h: \\mathcal{X} \\rightarrow \\mathcal{Y}$ a prediction rule, also called a *predictor*, *classifier*.\n",
    "\n",
    "An **hypothesis class** $\\mathcal{H}$ is some space of functions. If no restrictions, it is the set of all measurable functions.\n",
    "\n",
    "<u>Example (linear classifiers):</u> $\\mathcal{H} = \\{h:x\\rightarrow w^Tx+b, w\\in \\mathbb{R}^d, b\\in \\mathbb{R}\\}$\n",
    "\n",
    "Given an algorithm A and a dataset S, we will write $h=\\mathcal{A}(\\mathcal{S}$, the output of our algorithm on S."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation -- RANDOM SAMPLE ASSUMPTION\n",
    "\n",
    "For now we assume that there is a true distribution $\\mathcal{D}$ of the data on $\\mathcal{X}$. The training examples are **IID** samples from D.\n",
    "\n",
    "<u>Example:</u> Sample images uniformly at random from a larger set.\n",
    "\n",
    "It is hard to satisfy: there is always a bias in the way the dataset is constructed.\n",
    "\n",
    "**Assumption of noiseless setting**: There exists a function $f: \\mathcal{X} \\rightarrow \\mathcal{Y}$ such that $y_i = f(x_i)$ for any  $1\\le i \\le n$\n",
    "\n",
    "We know neither $\\mathcal{D}$ nor $f$! We only have access to $\\mathcal{S}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure of success\n",
    "\n",
    "**Risk of a classifier**: Probability that h does not return the correct label on a (new) random sample:\n",
    "\n",
    "> $\\mathcal{R}_{\\mathcal{D},f}(h) = \\mathbb{P}_{x \\rightsquigarrow \\mathcal{D}}(h(x) \\neq f(x))$\n",
    "\n",
    "**Intuition**: We want to be good, on average, for new samples of the same distribution. Subscript is often omitted when clear from cotnext. It is also gcalled the *generalization error, true error* (notation $\\mathcal{L}$ or $\\mathcal{\\epsilon}$)\n",
    "\n",
    "> WE WANT TO FIND h WITH SMALL GENERALIZATION ERROR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Empirical Risk Minimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$h\\in \\underset{h\\in \\mathcal{H}}{\\,argmin}\\,\\mathcal{R}_{\\mathcal{D},f}(h)=\\underset{h\\in \\mathcal{H}}{\\,argmin}\\,\\mathbb{P}_{x \\rightsquigarrow \\mathcal{D}}(h(x) \\neq f(x))$$\n",
    "\n",
    "We know neither D nor f. \n",
    "\n",
    "**Idea**: Replace $L_{\\mathcal{D},f}$ by an *empirical* version\n",
    "\n",
    "$$\\hat{\\mathcal{R_S}}(h)=\\frac{1}{n}\\,|i\\in\\{1, ..., n\\}\\quad {s.t.}\\quad h(x_i)\\neq y_i|$$\n",
    "\n",
    "We want to minimize the empirical risk (perform ERM)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
