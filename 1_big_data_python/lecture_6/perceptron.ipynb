{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OR GATE PERCEPTRON\n",
    "\n",
    "In this notebook we will implement a perceptron for the OR GATE.\n",
    "\n",
    "Remember the `OR` gate works as follows:\n",
    "\n",
    "| X1    | X2       | Out  |\n",
    "| :-----: |:--------:| :----:|\n",
    "|   0   |    0     |   0  |\n",
    "|   0   |    1     |   1  |\n",
    "|   1   |    0     |   1  |\n",
    "|   1   |    1     |   1  |\n",
    "\n",
    "And the corresponding perceptron is:\n",
    "\n",
    "\n",
    "![Image](https://marcomilanesio.github.io/material/5/perceptron.png)\n",
    "\n",
    "### Assign random weigths and calculate output\n",
    "\n",
    "Let's assign the following weights at random: \n",
    "  * $w_1 = 0.2$\n",
    "  * $w_2 = 0.3$\n",
    "  * $w_3 = 0.5$\n",
    "  \n",
    "Let's assume:\n",
    "  * $x_1 = 0$\n",
    "  * $x_2 = 1$\n",
    "  \n",
    "Then we can compute:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### input for $o_1$\n",
    "\n",
    "\\begin{align}\n",
    "o_1 & = w_1 * x_1 + w_2 * x_2 + w3 * b \\\\\n",
    "    & = 0.3 + 0.5 \\\\\n",
    "    & = 0.8\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "#### output value (using the `sigmoid` function):\n",
    "\n",
    "\\begin{align}\n",
    "out & = \\frac{1}{1 + e^{-X}} = \\frac{1}{1 + e^{-0.8}} = 0.68997\n",
    "\\end{align}\n",
    "\n",
    "#### error (MSE):\n",
    "\n",
    "\\begin{align}\n",
    "MSE & = \\sum_{i} \\frac{1}{2} * (target - output)^2\n",
    "\\end{align}\n",
    "\n",
    "In $o_1$:\n",
    "\n",
    "\\begin{align}\n",
    "err & = \\frac{1}{2} * (1 - 0.68997)^2 = 0.048059\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "We need to calculate this for all possible inputs, and then calculate the global MSE.\n",
    "\n",
    "After this, we can update the weights.\n",
    "So,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent\n",
    "\n",
    "\\begin{align}\n",
    "X & = X - lr * \\frac{\\partial}{\\partial X} f(X)\n",
    "\\end{align}\n",
    "\n",
    "Where:\n",
    "  * $X$ is the input\n",
    "  * $lr$ is the learning rate\n",
    "  * $f(X)$ is the output\n",
    "  \n",
    "### Derivation\n",
    "\n",
    "#### N.1: how a particular weight $w$ influence the error $err$?\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\partial err}{\\partial w}\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "Let's apply [Chain Rule](https://en.wikipedia.org/wiki/Chain_rule).\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\partial err}{\\partial w} = \\frac{\\partial err}{\\partial out} * \\frac{\\partial out}{\\partial in} * \\frac{\\partial in}{\\partial w}\n",
    "\\end{align}\n",
    "\n",
    "Where (I'll skip the derivation, if interested ask me)\n",
    "\n",
    "  * $\\frac{\\partial err}{\\partial out} = (output - target)$\n",
    "  * $\\frac{\\partial out}{\\partial in} = output * (1 - output)$\n",
    "  * $\\frac{\\partial in}{\\partial w} = input$\n",
    "\n",
    "And remember:\n",
    "  * $input = w_1 * x_1 + w_2 * x_2 + w_3 * b$\n",
    "  * $output = \\frac{1}{1 + e^{-input}}$\n",
    "  * $MSE = \\sum \\frac{1}{2} (target - output)^2$\n",
    "  * Gradient Descent $w = w - lr * \\frac{\\partial err}{\\partial w}$\n",
    "  \n",
    "  \n",
    "## LET'S DO IT!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 2)\n",
      "[[0]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "input_features = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
    "target_output = np.array([[0,1,1,1]])\n",
    "target_output = target_output.reshape(4,1)\n",
    "\n",
    "print(input_features.shape)\n",
    "print(target_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x)*(1-sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.34016512]\n",
      " [0.60143311]]\n"
     ]
    }
   ],
   "source": [
    "weights = np.random.rand(2,1) #np.array([[0.1], [0.2]])\n",
    "print(weights)\n",
    "bias = 0.3\n",
    "learning_rate=0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, error: -0.2836806920826571\n",
      "epoch 1000, error: 0.03367278503551974\n",
      "epoch 2000, error: 0.009542414059545673\n",
      "epoch 3000, error: 0.0038118061304079076\n",
      "epoch 4000, error: 0.0017639619281635543\n",
      "epoch 5000, error: 0.0008557228052071542\n",
      "epoch 6000, error: 0.0003967629348268359\n",
      "epoch 7000, error: 0.000144268347174778\n",
      "epoch 8000, error: -2.783176885359784e-06\n",
      "epoch 9000, error: -9.169477688272115e-05\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10000):\n",
    "    # input\n",
    "    inputs = input_features\n",
    "    # feed-forward input\n",
    "    in_o = np.dot(inputs, weights) + bias #shape(4,2) dot shape(2,1) -> np.dot is of shape(4,1)\n",
    "    # feed-forward output\n",
    "    out_o = sigmoid(in_o)\n",
    "    \n",
    "    # error\n",
    "    error = out_o - target_output #result in [0,1] range\n",
    "    x = error.sum()\n",
    "    if epoch % 1000 == 0: print(f\"epoch {epoch}, error: {x}\")\n",
    "    \n",
    "    # back-propagation\n",
    "    derr_dout = error\n",
    "    dout_din = sigmoid_derivative(out_o)\n",
    "    deriv = derr_dout * dout_din\n",
    "    inputs = input_features.T\n",
    "    deriv_final = np.dot(inputs, deriv) # shape(4,1)\n",
    "    \n",
    "    # weight updating\n",
    "    weights -= learning_rate * deriv_final\n",
    "    \n",
    "    for i in deriv:\n",
    "        bias -= learning_rate * i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.02260341],\n",
       "       [7.02352136]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.15601742])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREDICTIONS for OR GATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.97949937]\n"
     ]
    }
   ],
   "source": [
    "# target = 1\n",
    "\n",
    "point = np.array([1,0])\n",
    "step1 = np.dot(point, weights) + bias\n",
    "step2 = sigmoid(step1)\n",
    "print(step2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99998136]\n"
     ]
    }
   ],
   "source": [
    "# target = 1\n",
    "\n",
    "point = np.array([1,1])\n",
    "step1 = np.dot(point, weights) + bias\n",
    "step2 = sigmoid(step1)\n",
    "print(step2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04085483]\n"
     ]
    }
   ],
   "source": [
    "# target = 1\n",
    "\n",
    "point = np.array([0,0])\n",
    "step1 = np.dot(point, weights) + bias\n",
    "step2 = sigmoid(step1)\n",
    "print(step2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
