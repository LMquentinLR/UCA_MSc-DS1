{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COURSE 5 - Basic Algrebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*October 7th, 2020*\n",
    "\n",
    "**Teacher**: Marco Corneli\n",
    "\n",
    "*Contacts on personal website:* https://math.unice.fr/~mcorneli/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reminder on Partial Derivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The partial derivatives of a function with respect to its points (e.g. in the case of dimension $N=2$, $x$ and $y$) is:\n",
    "\n",
    "### 1. Case of $N=2$\n",
    "\n",
    "1. Point $x$: $\\frac{\\delta f}{\\delta x}(x,y)=\\lim_{h\\rightarrow0}\\frac{f(x+h,y)-f(x,y)}{h}=f_x(x,y)$\n",
    "\n",
    "2. Point $y$: $\\frac{\\delta f}{\\delta x}(x,y)=\\lim_{h\\rightarrow0}\\frac{f(x,y+h)-f(x,y)}{h}=f_y(x,y)$\n",
    "\n",
    "For the partial derivatives to exist, the limits above **must exist** and **be finite**.\n",
    "\n",
    "The partial derivatives of a function have a **gradient**: The column vector formed with each partial derivatives of f, noted $\\nabla_f$\n",
    "\n",
    "\n",
    "### 2. General Case\n",
    "\n",
    "The general case corresponds to the concept of **directional derivatives**, such that:\n",
    "\n",
    "> $f:\\mathbb{R}^N \\rightarrow \\mathbb{R}$, $x_0 \\in \\mathbb{R}$ and $x=x_0+t.v$ with $||v|| = 1$\n",
    "\n",
    "We note:\n",
    "\n",
    "1. $\\frac{\\delta f}{\\delta v}(x_0)=\\lim_{t\\rightarrow0}\\frac{f(x_0+t.v)-f(x_0)}{t}$\n",
    "\n",
    "2. $g(t) = f(x_0 + t.v) \\Rightarrow \\frac{\\delta f}{\\delta v}(x_0) = g'(x_0)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proposition 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> $f:A \\rightarrow \\mathbb{R}$ with $A \\subset\\mathbb{R}^N$\n",
    ">\n",
    "> $x_0 \\in \\dot{A}$ with $\\dot{A}$ the interior of $A$\n",
    "\n",
    "if $x_0$ is a relative minimum or relative maximum of f, then if $\\frac{\\delta f}{\\delta v}$ exists for some v then $\\frac{\\delta f}{\\delta v}(x_0)=0$. i.e.\n",
    "\n",
    "> if $\\frac{\\delta f}{\\delta v}(x_0)$, $\\exists v \\in \\mathbb{R}^N$ with $||v||=1$ then $\\frac{\\delta f}{\\delta v}(x_0)=0$\n",
    "\n",
    "### Proof\n",
    "\n",
    "$g(t) = f(x+t.v)$ is well defined for all $t$ such that $x_0 +t.v \\in A$\n",
    "\n",
    "** Case of Relative Minimum**:\n",
    "\n",
    "$f(x_0 + t.v) \\ge f(x_0)$ eq. $g(t) \\ge g(0)$\n",
    "\n",
    "$\\Rightarrow t$ is a local minimum for $g$ if $g'(0)$ exists then $g'(0) = 0$ but $g'(0) = \\frac{\\delta f}{\\delta v}(x_0)$\n",
    "\n",
    "\n",
    "### /!\\\n",
    "\n",
    "When $N\\gt1$, existence of f gradient does not prove continuity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differentiability\n",
    "\n",
    "### Definition\n",
    "> Given $f:\\mathbb{R}^N \\rightarrow \\mathbb{R}$ is differentiable with $x_0 \\in \\mathbb{R}^N$ if $\\exists\\nabla_{f(x_0)}$ and $\\lim_{x\\rightarrow x_0}\\frac{f(x) - f(x_0) - <\\nabla_{f(x_0)}, x-x_0>}{||x - x_0||}=0$\n",
    "\n",
    "### Theorem\n",
    "If f is differentiable at point $x_0$ then:\n",
    "\n",
    "1. f is continuous at x_0\n",
    "\n",
    "2. The derivative of $f_{x_0} = \\frac{\\delta f}{\\delta v}(x_0) = <\\nabla_{f(x_0)},v>$ \n",
    "\n",
    "### Proof\n",
    "\n",
    "1. **step 1**\n",
    "\n",
    "$f$ is continuous at $x_0$ if $\\lim_{f(x)} = f(x_0) \\Leftrightarrow \\lim_{x\\rightarrow x_0} \\lceil f(x) - f(x_0)\\rceil = 0$\n",
    "\n",
    "$f(x) - f(x_0) = \\frac{f(x) - f(x_0) - <\\nabla_{f(x_0)}, x-x_0>}{||x-x_0||}*||x-x_0||+<\\nabla_{f(x_0)}, x-x_0>$\n",
    "\n",
    "When $x \\rightarrow x_0$, $lim = 0$\n",
    "\n",
    "\n",
    "2. **step 2**\n",
    "\n",
    "Set $x = x_0 + t.v$ i.e. $t.v = x - x_0$\n",
    "\n",
    "$lim_{t\\rightarrow0}\\frac{f(x) - f(x_0) - <\\nabla_{f(x_0)}, x-x_0>}{||x-x_0||}=lim_{t\\rightarrow0}\\frac{f(x_0+t.v) - f(x_0) - <\\nabla_{f(x_0)}, t.v>}{||t.v||} = lim_{t\\rightarrow0}\\frac{f(x_0+t.v) - f(x_0)}{|t|}$ with $|t|.||v|| = 1$\n",
    "\n",
    "$lim_{t\\rightarrow0}\\frac{<\\nabla_{f(x_0)}, t.v>}{|t|} = lim_{t\\rightarrow0}\\frac{t.<\\nabla_{f(x_0)}, v>}{|t|}= lim_{t\\rightarrow0}.<\\nabla_{f(x_0)}, v>$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use of Cauchy-Schwartz\n",
    "\n",
    "$|<v,w>| \\le ||v||.||w||$ eq. CS turns into an equality if and only if $v$ and $w$ are linearly dependent i.e. $v = \\alpha . w$\n",
    "\n",
    "### Proof\n",
    "\n",
    "Let's choose a direction $v = \\frac{\\nabla_{f(x_0)}}{||\\nabla_{f(x_0)}||} \\Rightarrow ||v|| = \\frac{1}{||\\nabla_{f(x_0)}||}.||\\nabla_{f(x_0)}||=1$\n",
    "\n",
    "$|\\frac{\\delta f}{\\delta v}(x_0)| = <\\nabla_{f(x_0)}, v> = <\\nabla_{f(x_0)},\\frac{\\nabla_{f(x_0)}}{||f(x_0)||}> = \\frac{1}{||\\nabla_{f(x_0)}||}.<\\nabla_{f(x_0)},\\nabla_{f(x_0)}> = \\frac{1}{||\\nabla_{f(x_0)}||}.||\\nabla_{f(x_0)}||^2=||\\nabla_{f(x_0)}||$\n",
    "\n",
    "Let's choose another direction $w$ with $|\\frac{\\delta f}{\\delta w}(x_0)| = <\\nabla_{f(x_0)},w> \\le ||\\nabla_{f(x_0)}||.||w|| \\le ||\\nabla_{f(x_0)}||.1 = |\\frac{\\delta f}{\\delta v}(x_0)|$\n",
    "\n",
    "$\\Rightarrow \\frac{\\delta f}{\\delta w}(x_0) \\le \\frac{\\delta f}{\\delta v}(x_0)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Higher Order Derivatives\n",
    "\n",
    "Give $f:\\mathbb{R}^N \\rightarrow \\mathbb{R}$ and $f(x_1, ..., x_n) \\in \\mathbb{R}$\n",
    "\n",
    "1. first order derivative: $\\frac{\\delta f}{\\delta x}: \\mathbb{R}^N \\rightarrow \\mathbb{R}$\n",
    "\n",
    "2. second order derivative: $\\frac{\\delta}{\\delta x_i}.\\frac{\\delta}{\\delta x_j}=\\frac{\\delta^2 f}{\\delta x_i.x_j}$\n",
    "\n",
    "The second order derivatives can be collected in a matrix denoted $H_{f(x_i,x_j)}\\in \\mathbb{R}^{NxN}$ called a Hessian matrix.\n",
    "\n",
    "> $H_f$ is such that $[H_f]_{j,i} = \\frac{\\delta^2 f}{\\delta x_{i,j}}$\n",
    "\n",
    "3. $\\frac{\\delta^2 f}{\\delta^2 x_i}$ is called a pure second order derivative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proof of local minimum for f\n",
    "\n",
    "### Proposition\n",
    "\n",
    "Consider $x_0 \\in A$ such that $\\nabla_{f(x_0)} = O_{\\mathbb{R}^N}$ and $H_{f(x_0)}$ is positive definite.\n",
    "\n",
    "**Then there is a mocal minimum for f**.\n",
    "\n",
    "### Proof\n",
    "\n",
    "\n",
    "$f(x) = f(x_0) + <\\nabla_{f(x_0)},x-x_0>+\\frac{1}{2}.(x-x_0)^T.H_{f(x_0)}(x-x_0)+\\circ(x-x_0)$\n",
    "\n",
    "Note: $\\circ(t^2) = \\circ(|t|.||v||)^2) = \\circ(||x-x_0||^2)$ since $||v|| = 1$\n",
    "\n",
    "$f(x) -f(x_0) = \\frac{1}{2}.(x-x_0)^T.H_{f(x_0)}.(x-x_0)+\\circ(||x-x_0||^2)$ with $<\\nabla_{f(x_0)},x-x_0> = 0$\n",
    "\n",
    "$\\frac{f(x) -f(x_0)}{||x-x_0||^2} = \\frac{1}{2}.\\frac{(x-x_0)^T}{||x-x_0||^2}.H_{f(x_0)}.\\frac{(x-x_0))}{||x-x_0||^2}+\\circ\\frac{||x-x_0||^2}{||x-x_0||^2}$\n",
    "\n",
    "By naming $v = \\frac{(x-x_0))}{||x-x_0||^2}$ we have $\\frac{1}{2}.v^T.H_{f(x_0)}.v$\n",
    "\n",
    "Note that when x is moving, so does v.\n",
    "\n",
    "The set $S$ such that $S = \\{v \\in \\mathbb{R}^N$,$ ||v||=1\\}$ can be shown to be compact.\n",
    "\n",
    "Then $v^T.H_{f(x_0)}.v$ admids a minimum over $S$, called $m$. That is $v^T.H_{f(x_0)}.v \\ge m \\ge 0$ by assumption.\n",
    "\n",
    "$\\Rightarrow \\frac{f(x) -f(x_0)}{||x-x_0||^2}$ can be minored by $\\frac{m}{2} + \\circ\\frac{||x-x_0||^2}{||x-x_0||}$ and by definition of $\\circ$ it follows that $ lim_{x\\rightarrow x_0}R(x, x_0) = 0$ \n",
    "\n",
    "It means that $\\forall \\epsilon \\gt 0$, $\\exists \\delta \\gt 0$ such that $\\forall x \\in \\mathbb{R}^N$, $ ||x-x_0|| \\gt \\delta \\Rightarrow |R(x, x_0)| \\lt \\epsilon$\n",
    "\n",
    "In the following instance $\\epsilon = \\frac{m}{4} \\Rightarrow \\exists \\delta$ such that $\\forall||x-x_0||\\lt\\delta\\Rightarrow -\\frac{m}{4}\\lt R(x, x_0)\\lt\\frac{m}{4}$\n",
    "\n",
    "And:\n",
    "\n",
    "$\\forall x \\in \\mathbb{R}^N$, $\\frac{f(x)-f(x_0)}{||x-x_0||^2}\\gt \\frac{m}{2}-\\frac{m}{4} = \\frac{m}{4}$ such that $||x-x_0|| \\lt \\delta$ \n",
    "\n",
    "$\\Rightarrow \\forall x\\in \\mathbb{R}^N$ such that $||x-x_0|| \\lt \\delta \\Rightarrow f(x_0)$ is a local minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
