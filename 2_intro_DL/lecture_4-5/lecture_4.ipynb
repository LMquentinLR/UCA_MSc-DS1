{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rfp1U9PMeQU1"
   },
   "source": [
    "\n",
    "# TP CNN\n",
    "### Diane LINGRAND \n",
    "\n",
    "diane.lingrand@univ-cotedazur.fr "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uo8ucmMpgEp9"
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "68uwyRRi4BMK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "import tensorflow\n",
    "print(tensorflow.__version__)\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Activation \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorflow.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZMrLWuFy9gn7"
   },
   "source": [
    "**The GPU**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TO0xCfDwz-zT"
   },
   "source": [
    "To enable GPU backend in Google colab for your notebook:\n",
    "\n",
    "1.   Runtime (top left corner) -> Change runtime type\n",
    "2.   Put GPU as \"Hardware accelerator\"\n",
    "3.   Save."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hHU7TK6FrHao"
   },
   "source": [
    "# Convolutional Neural Networks (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eP0L5uYbfAzC"
   },
   "source": [
    "Derived from the MLP, a convolutional neural network (CNN) is a type of artificial neural network that is specifically designed to process **pixel data**.  The layers of a CNN consist of an **input layer**, an **output layer** and **hidden layers** that can include **convolutional layers**, **pooling layers**, **fully connected layers** and **normalization layers**. It exists a lot of techniques to optimize CNN, like for example the dropout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bfCDrvt8qQPY"
   },
   "source": [
    "## Loading the dataset\n",
    "In this part, we will use photographies of animals from the kaggle dataset [animals-10](https://www.kaggle.com/alessiocorrado99/animals10). Please connect to their site before loading the dataset from this [zip file](http://www.i3s.unice.fr/~lingrand/raw-img.zip). Decompress the zip file on your disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RM78thFqt-ZY"
   },
   "source": [
    "To feed the data to a CNN, we need to shape it as required by Keras. As input, a 2D convolutional layer needs a **4D tensor** with shape: **(batch, rows, cols, channels)**. Therefore, we need to precise the \"channels\" axis, which can be seen as the number of level of color of each input: 3 channels in our case. We will fix the dimension of images according to the VGG-16 network: (224, 224).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i_yPS5rYF1Sk"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, MaxPooling2D\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "import glob\n",
    "#!pip install tqdm\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IzHkKLqlZPn3"
   },
   "source": [
    "### loading train data\n",
    "\n",
    "Please read the code before running any of the cells!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/qlr/Programming/UCA_MSc-DS1/2_intro_DL/lecture_4'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "root = os.getcwd()\n",
    "datasetRoot=root+'/raw-img/'\n",
    "root"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gU_b3QQGZO58"
   },
   "source": [
    "# WARNING: do not run this cell now. It is very time consuming. Run the next one and come back here if you have time later.\n",
    "datasetRoot=root+'/'\n",
    "classes = ['mucca', 'elefante', 'gatto', 'cavallo', 'scoiattolo', 'ragno', 'pecora', 'farfalla', 'gallina', 'cane']\n",
    "\n",
    "\n",
    "#training data\n",
    "\n",
    "rootTrain = datasetRoot+'train/'\n",
    "classLabel = 0\n",
    "\n",
    "xTrain = np.empty(shape=(0,224,224,3))\n",
    "yTrain = []\n",
    "first = True\n",
    "for cl in tqdm(classes):\n",
    "    listImages = glob.glob(rootTrain+cl+'/*')\n",
    "    yTrain += [classLabel]*100#len(listImages) # note that here ...\n",
    "    for pathImg in tqdm(listImages[:100]): # and here, we have reduced the data to be loaded (only 100 per class)\n",
    "        img = image.load_img(pathImg, target_size=(224, 224))\n",
    "        im = image.img_to_array(img)\n",
    "        im = np.expand_dims(im, axis=0)\n",
    "        im = preprocess_input(im)\n",
    "        xTrain = np.vstack([xTrain, im])\n",
    "    classLabel += 1\n",
    "print(len(yTrain))\n",
    "print(xTrain.shape)\n",
    "yTrain = keras.utils.to_categorical(yTrain, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when processing time is long, it's nice to see the progress bar\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xkVd3v4N3LnB"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 48/1492 [00:00<00:03, 477.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/qlr/Programming/UCA_MSc-DS1/2_intro_DL/lecture_4/raw-img/train/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1492/1492 [00:03<00:00, 488.70it/s]\n",
      "100%|██████████| 1156/1156 [00:03<00:00, 327.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5296\n",
      "(5296, 224, 224, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "classes = ['mucca', 'elefante'] #, gatto', 'cavallo', 'scoiattolo', 'ragno', 'pecora', 'farfalla', 'gallina', 'cane']\n",
    "nbClasses = len(classes)\n",
    "\n",
    "#training data\n",
    "rootTrain = datasetRoot+'train/'\n",
    "print(rootTrain)\n",
    "\n",
    "classLabel = 0\n",
    "reducedSizePerClass = 1156+1492 #in order to reduce the number of images per class\n",
    "totalImg = nbClasses * reducedSizePerClass\n",
    "xTrain = np.empty(shape=(totalImg,224,224,3))\n",
    "yTrain = []\n",
    "first = True\n",
    "i= 0\n",
    "for cl in classes:\n",
    "    listImages = glob.glob(rootTrain+cl+'/*')\n",
    "    yTrain += [classLabel]*reducedSizePerClass #len(listImages) # note that here ...\n",
    "    for pathImg in tqdm(listImages[:reducedSizePerClass]): # and here, we have reduced the data to be loaded (only 1000 per class)\n",
    "        img = image.load_img(pathImg, target_size=(224,224))\n",
    "        im = image.img_to_array(img)\n",
    "        im = np.expand_dims(im, axis=0)\n",
    "        im = preprocess_input(im)\n",
    "        xTrain[i,:,:,:] = im\n",
    "        i += 1\n",
    "    classLabel += 1\n",
    "print(len(yTrain))\n",
    "print(xTrain.shape)\n",
    "\n",
    "yTrain = tensorflow.keras.utils.to_categorical(yTrain, nbClasses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "56bq9oXanGUm"
   },
   "source": [
    "In order to speed-up the time spent on this part of the lab, you may have noticed that we reduced the number of classes and the number of images per class. You can change these few lines of code if you want to work on the whole dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "boNapUgGaEMj"
   },
   "source": [
    "### loading test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zwi5TBlKajtt",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "664\n",
      "(664, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "#you will probably need to reduce the test dataset according to the train dataset rules\n",
    "rootTest = datasetRoot+'test/'\n",
    "classLabel = 0\n",
    "\n",
    "totalTestImg = 0\n",
    "for cl in classes:\n",
    "    totalTestImg += len(glob.glob(rootTest+cl+'/*'))\n",
    "\n",
    "xTest = np.empty(shape=(totalTestImg,224,224,3))\n",
    "yTest = []\n",
    "i = 0\n",
    "\n",
    "for cl in classes:\n",
    "    listImages = glob.glob(rootTest+cl+'/*')\n",
    "    yTest += [classLabel]*len(listImages)\n",
    "    for pathImg in listImages:\n",
    "        img = image.load_img(pathImg, target_size=(224, 224))\n",
    "        im = image.img_to_array(img)\n",
    "        im = np.expand_dims(im, axis=0)\n",
    "        im = preprocess_input(im)\n",
    "        xTest[i,:,:,:] = im \n",
    "    classLabel += 1\n",
    "print(len(yTest))\n",
    "print(xTest.shape)\n",
    "yTest = tensorflow.keras.utils.to_categorical(yTest, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yTrain[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Build your own CNN network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with the simplest CNN: 1 conv2D layer + 1 pooling + 1 dense layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(64,(3,3),padding='same',activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3),padding='same'))\n",
    "model.add(Conv2D(64,(3,3),padding='same',activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3),padding='same'))\n",
    "model.add(Conv2D(32,(3,3),padding='same',activation='relu'))\n",
    "model.add(Flatten())\n",
    "# you probably need to add something here\n",
    "model.add(Dense(nbClasses, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn and test this network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "530/530 [==============================] - 17s 28ms/step - loss: 0.5965 - accuracy: 0.9808 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 2/3\n",
      "530/530 [==============================] - 14s 26ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 3/3\n",
      "530/530 [==============================] - 14s 26ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    xTrain,\n",
    "    yTrain,\n",
    "    batch_size=8,\n",
    "    epochs=3,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [0.1764330118894577, 0.0, 0.0], 'accuracy': [0.9962228536605835, 1.0, 1.0], 'val_loss': [0.0, 0.0, 0.0], 'val_accuracy': [1.0, 1.0, 1.0]}\n"
     ]
    }
   ],
   "source": [
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on test data\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 13.9967 - accuracy: 0.4383\n",
      "test loss, test acc: [13.99670124053955, 0.4382530152797699]\n",
      "Generate predictions for 3 samples\n",
      "predictions shape: (3, 2)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data using `evaluate`\n",
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(xTest, yTest, batch_size=8)\n",
    "print(\"test loss, test acc:\", results)\n",
    "\n",
    "# Generate predictions (probabilities -- the output of the last layer)\n",
    "# on new data using `predict`\n",
    "print(\"Generate predictions for 3 samples\")\n",
    "predictions = model.predict(xTest[:3])\n",
    "print(\"predictions shape:\", predictions.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will encounter errors telling you that some dimensions are incompatible. Why ? How to correct ?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# for you !\n",
    "\n",
    "to categorical => 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to modify the architecture and some of the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorflow.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HDg_e-Ax3uci"
   },
   "source": [
    "## About Dropout \n",
    "\n",
    "*Study this part only if you have time for it. It concerns the previous network but prefer to study first part II and come back here after.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eC5ct2L36pKC"
   },
   "source": [
    "**Let's add dropout and activation functions to the network!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y20GTiux6uy9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 222, 222, 256)     7168      \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 200)               51400     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 402       \n",
      "=================================================================\n",
      "Total params: 58,970\n",
      "Trainable params: 58,970\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "model = Sequential(name='MLP model with dropout') \n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(256,(3,3),activation='relu',input_shape=(224,224,3)))\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(200,activation='relu'))\n",
    "# adding dropout to the previous layer\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(nbClasses, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "530/530 [==============================] - 20s 37ms/step - loss: 0.0963 - accuracy: 0.9848 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 2/3\n",
      "530/530 [==============================] - 19s 35ms/step - loss: 1.6313e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 3/3\n",
      "530/530 [==============================] - 19s 35ms/step - loss: 1.8065e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    xTrain,\n",
    "    yTrain,\n",
    "    batch_size=8,\n",
    "    epochs=3,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on test data\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 12.5191 - accuracy: 0.4383\n",
      "test loss, test acc: [12.519134521484375, 0.4382530152797699]\n",
      "Generate predictions for 3 samples\n",
      "predictions shape: (3, 2)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data using `evaluate`\n",
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(xTest, yTest, batch_size=8)\n",
    "print(\"test loss, test acc:\", results)\n",
    "\n",
    "# Generate predictions (probabilities -- the output of the last layer)\n",
    "# on new data using `predict`\n",
    "print(\"Generate predictions for 3 samples\")\n",
    "predictions = model.predict(xTest[:3])\n",
    "print(\"predictions shape:\", predictions.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Using a pre-learned network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Og1KZntwavZT"
   },
   "source": [
    "## loading VGG-16 description part and adding layers to build our own classification network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ofrQr-x_a-Bi"
   },
   "outputs": [],
   "source": [
    "VGGmodel = VGG16(weights='imagenet', include_top=False)\n",
    "features = VGGmodel.predict(xTrain)\n",
    "print(features.shape)\n",
    "\n",
    "# we will add layers to this feature extraction part of VGG network\n",
    "m = VGGmodel.output\n",
    "# we start with a global average pooling\n",
    "m = GlobalAveragePooling2D()(m)\n",
    "# and add a fully-connected layer\n",
    "m = Dense(1024, activation='relu')(m)\n",
    "# finally, the softmax layer for predictions (we have nbClasses classes)\n",
    "predictions = Dense(nbClasses, activation='softmax')(m)\n",
    "\n",
    "# global network\n",
    "model = Model(inputs=VGGmodel.input, outputs=predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6POPQoXcbPuc"
   },
   "source": [
    "Can you display the architecture of this entire network?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PrLUhA2-b8Fv"
   },
   "outputs": [],
   "source": [
    "# training\n",
    "ourCallback = tensorflow.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0.0001, patience=20, verbose=0, mode='auto', baseline=None, restore_best_weights=False)\n",
    " \n",
    "# training part I: training only the classification part (the end)\n",
    "for layer in VGGmodel.layers:\n",
    "    layer.trainable = False\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(xTrain, yTrain, epochs=2000, batch_size=128, validation_split=0.2, callbacks=[ourCallback],verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4hgDguiNcNXZ"
   },
   "source": [
    "# fine-tune the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L9jmknEpcT1_"
   },
   "source": [
    "Fine-tune the entire network if you have enough computing ressouces, otherwise, carefully choose the layers you want to fine-tune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cRr97-2yc6kZ"
   },
   "outputs": [],
   "source": [
    "for i, layer in enumerate(VGGmodel.layers):\n",
    "   print(i, layer.name)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v4eCse6wku5Q"
   },
   "source": [
    "In this example, we will fine-tune the last convolution block starting at layer number 15 (block5_conv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C17ts6kllGUr"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "for layer in model.layers[:15]:\n",
    "   layer.trainable = False\n",
    "for layer in model.layers[15:]:\n",
    "   layer.trainable = True\n",
    "#need to recompile the network\n",
    "model.compile(optimizer=RMSprop(learning_rate=0.0001), loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "#and train again ...\n",
    "model.fit(xTrain, yTrain, epochs=2000, batch_size=128, validation_split=0.2, callbacks=[ourCallback],verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6LrhxQiBmTZj"
   },
   "source": [
    "You already know how to evaluate the performances on the test dataset and display the confusion matrix. You can also modify the code that loads the test dataset in order to reduce it's size. Let's do it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RHGxb-PxmiYd"
   },
   "outputs": [],
   "source": [
    "#enter here your code for evaluation of performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "unzKoPOsgNW3"
   },
   "source": [
    "You are now free to experiments changes in the network:\n",
    "* add a dense layer\n",
    "* modify the number of neurons in dense layer(s)\n",
    "* change the global average polling\n",
    "* experiment other optimizers (SGD, Adam, ...)\n",
    "\n",
    "\n",
    "..."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ImageClassificationUsingDeepLearning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
