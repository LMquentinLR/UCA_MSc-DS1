{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rfp1U9PMeQU1"
   },
   "source": [
    "\n",
    "# TP adversarial images\n",
    "### Diane LINGRAND \n",
    "\n",
    "diane.lingrand@univ-cotedazur.fr "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uo8ucmMpgEp9"
   },
   "source": [
    "# Introduction\n",
    "inspired by examples from https://foolbox.readthedocs.io/en/stable/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall foolbox -y\n",
    "!pip install foolbox==2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "68uwyRRi4BMK"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'LinfProjectedGradientDescentAttack' from 'foolbox.attacks' (/home/qlr/anaconda3/lib/python3.8/site-packages/foolbox/attacks/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-67a0aaf7c623>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfoolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensorFlowModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfoolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfoolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLinfProjectedGradientDescentAttack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'LinfProjectedGradientDescentAttack' from 'foolbox.attacks' (/home/qlr/anaconda3/lib/python3.8/site-packages/foolbox/attacks/__init__.py)"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import foolbox\n",
    "import tensorflow as tf\n",
    "import eagerpy as ep\n",
    "from foolbox.models import TensorFlowModel, Model\n",
    "from foolbox.utils import accuracy, samples\n",
    "from foolbox.attacks import LinfProjectedGradientDescentAttack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hHU7TK6FrHao"
   },
   "source": [
    "# LinfPG attack\n",
    "Linf PGD stands for Projected Gradient Descent. In this attack, the model is known and will be used for the gradient descent. At each step, a neighborhood ball around the current position is examined (radius corresponding to the maximum amount of perturbation) for searching the minimum loss function value. The projection corresponds to moving the current position to the minimal loss function value position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the ResNet50 network\n",
    "model = tf.keras.applications.ResNet50(weights=\"imagenet\")\n",
    "pre = dict(flip_axis=-1, mean=[104.0, 116.0, 123.0])  # RGB to BGR\n",
    "\n",
    "fmodel = foolbox.models.TensorFlowModel(model, bounds=(0, 255), preprocessing=pre)\n",
    "fmodel = fmodel.transform_bounds((0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# computing the accuracy of the ResNet50 network on the imagenet dataset\n",
    "\n",
    "images, labels = samples(fmodel, dataset=\"imagenet\", batchsize=16)\n",
    "acc = accuracy(fmodel, images, labels)\n",
    "\n",
    "print(\"accuracy:\", acc * 100 ,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#attack definition and computation (launch this box and go for a coffee)\n",
    "epsilons = [0.001, 0.01, 0.1, 0.5]\n",
    "\n",
    "attack = LinfPGD()\n",
    "raw_advs, clipped_advs, success = attack(fmodel, images, labels, epsilons=epsilons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(success.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calculate and report the robust accuracy (the accuracy of the model when it is attacked)\n",
    "\n",
    "robust_accuracy = 1 - np.mean(success, axis=-1)\n",
    "\n",
    "print(\"robust accuracy for perturbations with\")\n",
    "for eps, acc in zip(epsilons, robust_accuracy):\n",
    "    \n",
    "    print(f\"  Linf norm ≤ {eps:<6}: {acc.item() * 100:4.1f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also manually check this\n",
    "# we will use the clipped advs instead of the raw advs, otherwise\n",
    "# we would need to check if the perturbation sizes are actually\n",
    "# within the specified epsilon bound\n",
    "\n",
    "print(\"we can also manually check this:\\n\")\n",
    "print(\"robust accuracy for perturbations with\")\n",
    "\n",
    "for eps, advs_ in zip(epsilons, clipped_advs):\n",
    "    acc2 = accuracy(fmodel, advs_, labels)\n",
    "    print(f\"  Linf norm ≤ {eps:<6}: {acc2 * 100:4.1f} %\")\n",
    "    perturb = np.linalg.norm(advs_ - images)\n",
    "    print(\"    perturbation sizes:\", perturb)\n",
    "    if acc2 == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(images.shape)\n",
    "print(type(images))\n",
    "print(type(images.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = advs_[0].numpy()\n",
    "l = np.array([img])\n",
    "print(l.shape)\n",
    "print(np.argmax(model.predict(l)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(labels.numpy()))\n",
    "print(labels.numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a random image, display its adversarial and difference with the original image for different values of epsilon\n",
    "index = random.randint(0,len(images)-1)\n",
    "image = images.numpy()\n",
    "img = image[index]\n",
    "lab = labels.numpy()\n",
    "print(\"original label:\",lab[index])\n",
    "plt.figure(figsize=(50,50))\n",
    "ligne = 0 \n",
    "\n",
    "for advs_ in (clipped_advs):\n",
    "    adv = advs_.numpy()[index]\n",
    "    diff = img - adv\n",
    "    plt.subplot(13, 3, 1+ligne)\n",
    "    plt.imshow(img)\n",
    "    plt.subplot(13, 3, 2+ligne)\n",
    "    plt.imshow(adv)\n",
    "    plt.subplot(13, 3, 3+ligne)\n",
    "    plt.imshow(np.abs(20*diff))\n",
    "    ligne += 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify the previous code in order to display the new label of adversarial images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#this is for helping you to display class names instead of class labels\n",
    "labels_path = tf.keras.utils.get_file('ImageNetLabels.txt','https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt')\n",
    "imagenet_labels = np.array(open(labels_path).read().splitlines())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you target a specific class ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for a random image, display its adversarial and difference with the original image for different values of epsilon\n",
    "index = random.randint(0,len(images)-1)\n",
    "image = images.numpy()\n",
    "img = image[index]\n",
    "lab = labels.numpy()\n",
    "ligne = 0\n",
    "\n",
    "for i, advs_ in enumerate(clipped_advs):\n",
    "    plt.figure(figsize=(5,15))\n",
    "    adv = advs_.numpy()[index]\n",
    "    res50_label = imagenet_labels[lab[index]+1]\n",
    "    pred = imagenet_labels[np.argmax(model.predict(np.array([adv])))+1]\n",
    "    #print(\"original label:\",lab[index])\n",
    "    print(f\"label original: {res50_label}, new label: {pred}, epsilon: {epsilons[i]}\")\n",
    "    plt.subplot(2*len(clipped_advs), 2, 1+ligne)\n",
    "    plt.imshow(img, label=\"sine\")\n",
    "    plt.subplot(2*len(clipped_advs), 2, 2+ligne)\n",
    "    plt.imshow(adv, label=\"sine\")\n",
    "    ligne += 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall foolbox -y\n",
    "!pip install foolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-0784fbb538d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mrobust\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \"\"\"\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0meagerpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfoolbox\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPyTorchModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchvision'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "A simple example that demonstrates how to run a single attack against\n",
    "a PyTorch ResNet-18 model for different epsilons and how to then report\n",
    "the robust accuracy.\n",
    "\"\"\"\n",
    "import torchvision.models as models\n",
    "import eagerpy as ep\n",
    "from foolbox import PyTorchModel, accuracy, samples\n",
    "from foolbox.attacks import LinfPGD\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    # instantiate a model (could also be a TensorFlow or JAX model)\n",
    "    model = models.resnet18(pretrained=True).eval()\n",
    "    preprocessing = dict(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], axis=-3)\n",
    "    fmodel = PyTorchModel(model, bounds=(0, 1), preprocessing=preprocessing)\n",
    "\n",
    "    # get data and test the model\n",
    "    # wrapping the tensors with ep.astensors is optional, but it allows\n",
    "    # us to work with EagerPy tensors in the following\n",
    "    images, labels = ep.astensors(*samples(fmodel, dataset=\"imagenet\", batchsize=4))\n",
    "    clean_acc = accuracy(fmodel, images, labels)\n",
    "    print(f\"clean accuracy:  {clean_acc * 100:.1f} %\")\n",
    "\n",
    "    # apply the attack\n",
    "    attack = LinfPGD()\n",
    "    epsilons = [\n",
    "        0.0,\n",
    "        0.0002,\n",
    "        0.0005,\n",
    "        0.0008,\n",
    "        0.001,\n",
    "        0.0015,\n",
    "        0.002,\n",
    "        0.003,\n",
    "        0.01,\n",
    "        0.1,\n",
    "        0.3,\n",
    "        0.5,\n",
    "        1.0,\n",
    "    ]\n",
    "    raw_advs, clipped_advs, success = attack(fmodel, images, labels, epsilons=epsilons)\n",
    "\n",
    "    # calculate and report the robust accuracy (the accuracy of the model when\n",
    "    # it is attacked)\n",
    "    robust_accuracy = 1 - success.float32().mean(axis=-1)\n",
    "    print(\"robust accuracy for perturbations with\")\n",
    "    for eps, acc in zip(epsilons, robust_accuracy):\n",
    "        print(f\"  Linf norm ≤ {eps:<6}: {acc.item() * 100:4.1f} %\")\n",
    "\n",
    "    # we can also manually check this\n",
    "    # we will use the clipped advs instead of the raw advs, otherwise\n",
    "    # we would need to check if the perturbation sizes are actually\n",
    "    # within the specified epsilon bound\n",
    "    print()\n",
    "    print(\"we can also manually check this:\")\n",
    "    print()\n",
    "    print(\"robust accuracy for perturbations with\")\n",
    "    for eps, advs_ in zip(epsilons, clipped_advs):\n",
    "        acc2 = accuracy(fmodel, advs_, labels)\n",
    "        print(f\"  Linf norm ≤ {eps:<6}: {acc2 * 100:4.1f} %\")\n",
    "        print(\"    perturbation sizes:\")\n",
    "        perturbation_sizes = (advs_ - images).norms.linf(axis=(1, 2, 3)).numpy()\n",
    "        print(\"    \", str(perturbation_sizes).replace(\"\\n\", \"\\n\" + \"    \"))\n",
    "        if acc2 == 0:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import eagerpy as ep\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    # instantiate a model (could also be a TensorFlow or JAX model)\n",
    "    model = tf.keras.applications.ResNet50(weights=\"imagenet\")\n",
    "    pre = dict(flip_axis=-1, mean=[104.0, 116.0, 123.0])  # RGB to BGR\n",
    "    fmodel: Model = TensorFlowModel(model, bounds=(0, 255), preprocessing=pre)\n",
    "    fmodel = fmodel.transform_bounds((0, 1))\n",
    "\n",
    "    # get data and test the model\n",
    "    # wrapping the tensors with ep.astensors is optional, but it allows\n",
    "    # us to work with EagerPy tensors in the following\n",
    "    images, labels = ep.astensors(*samples(fmodel, dataset=\"imagenet\", batchsize=16))\n",
    "    clean_acc = accuracy(fmodel, images, labels)\n",
    "    print(f\"clean accuracy:  {clean_acc * 100:.1f} %\")\n",
    "\n",
    "    # apply the attack\n",
    "    attack = LinfPGD()\n",
    "    epsilons = [\n",
    "        0.0,\n",
    "        0.0002,\n",
    "        0.0005,\n",
    "        0.0008,\n",
    "        0.001,\n",
    "        0.0015,\n",
    "        0.002,\n",
    "        0.003,\n",
    "        0.01,\n",
    "        0.1,\n",
    "        0.3,\n",
    "        0.5,\n",
    "        1.0,\n",
    "    ]\n",
    "    raw_advs, clipped_advs, success = attack(fmodel, images, labels, epsilons=epsilons)\n",
    "\n",
    "    # calculate and report the robust accuracy (the accuracy of the model when\n",
    "    # it is attacked)\n",
    "    robust_accuracy = 1 - success.float32().mean(axis=-1)\n",
    "    print(\"robust accuracy for perturbations with\")\n",
    "    for eps, acc in zip(epsilons, robust_accuracy):\n",
    "        print(f\"  Linf norm ≤ {eps:<6}: {acc.item() * 100:4.1f} %\")\n",
    "\n",
    "    # we can also manually check this\n",
    "    # we will use the clipped advs instead of the raw advs, otherwise\n",
    "    # we would need to check if the perturbation sizes are actually\n",
    "    # within the specified epsilon bound\n",
    "    print()\n",
    "    print(\"we can also manually check this:\")\n",
    "    print()\n",
    "    print(\"robust accuracy for perturbations with\")\n",
    "    for eps, advs_ in zip(epsilons, clipped_advs):\n",
    "        acc2 = accuracy(fmodel, advs_, labels)\n",
    "        print(f\"  Linf norm ≤ {eps:<6}: {acc2 * 100:4.1f} %\")\n",
    "        print(\"    perturbation sizes:\")\n",
    "        perturbation_sizes = (advs_ - images).norms.linf(axis=(1, 2, 3)).numpy()\n",
    "        print(\"    \", str(perturbation_sizes).replace(\"\\n\", \"\\n\" + \"    \"))\n",
    "        if acc2 == 0:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ImageClassificationUsingDeepLearning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
