{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study: Sentiment Analysis\n",
    "\n",
    "In this lab we use part of the 'Amazon_Unlocked_Mobile.csv' dataset published by Kaggle. The dataset contain the following information:\n",
    "* Product Name\n",
    "* Brand Name\n",
    "* Price\n",
    "* Rating\n",
    "* Reviews\n",
    "* Review Votes\n",
    "\n",
    "We are mainly interested by the 'Reviews' (X) and by the 'Rating' (y)\n",
    "\n",
    "The goal is to try to predict the 'Rating' after reading the 'Reviews'. I've prepared for you TRAIN and TEST set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Load-dataset\" data-toc-modified-id=\"Load-dataset-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Load dataset</a></span></li><li><span><a href=\"#Build-X-(features-vectors)-and-y-(labels)\" data-toc-modified-id=\"Build-X-(features-vectors)-and-y-(labels)-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Build X (features vectors) and y (labels)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Construct-X_train-and-y_train\" data-toc-modified-id=\"Construct-X_train-and-y_train-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Construct X_train and y_train</a></span></li><li><span><a href=\"#Construct-X_test-and-y_test\" data-toc-modified-id=\"Construct-X_test-and-y_test-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Construct X_test and y_test</a></span></li></ul></li><li><span><a href=\"#Construct-a-Baseline\" data-toc-modified-id=\"Construct-a-Baseline-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Construct a Baseline</a></span></li><li><span><a href=\"#A-better-classifier-with-a-preprocessing\" data-toc-modified-id=\"A-better-classifier-with-a-preprocessing-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>A better classifier with a preprocessing</a></span></li><li><span><a href=\"#Summarize-your-conclusion-here\" data-toc-modified-id=\"Summarize-your-conclusion-here-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Summarize your conclusion here</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T09:02:28.458969Z",
     "start_time": "2020-12-03T09:02:28.436728Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T09:02:29.361117Z",
     "start_time": "2020-12-03T09:02:29.146934Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Review Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Samsung Galaxy Note 4 N910C Unlocked Cellphone...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>449.99</td>\n",
       "      <td>4</td>\n",
       "      <td>I love it!!! I absolutely love it!! üëåüëç</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BLU Energy X Plus Smartphone - With 4000 mAh S...</td>\n",
       "      <td>BLU</td>\n",
       "      <td>139.00</td>\n",
       "      <td>5</td>\n",
       "      <td>I love the BLU phones! This is my second one t...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apple iPhone 6 128GB Silver AT&amp;T</td>\n",
       "      <td>Apple</td>\n",
       "      <td>599.95</td>\n",
       "      <td>5</td>\n",
       "      <td>Great phone</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BLU Advance 4.0L Unlocked Smartphone -US GSM -...</td>\n",
       "      <td>BLU</td>\n",
       "      <td>51.99</td>\n",
       "      <td>4</td>\n",
       "      <td>Very happy with the performance. The apps work...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Huawei P8 Lite US Version- 5 Unlocked Android ...</td>\n",
       "      <td>Huawei</td>\n",
       "      <td>198.99</td>\n",
       "      <td>5</td>\n",
       "      <td>Easy to use great price</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Product Name Brand Name   Price  \\\n",
       "0  Samsung Galaxy Note 4 N910C Unlocked Cellphone...    Samsung  449.99   \n",
       "1  BLU Energy X Plus Smartphone - With 4000 mAh S...        BLU  139.00   \n",
       "2                   Apple iPhone 6 128GB Silver AT&T      Apple  599.95   \n",
       "3  BLU Advance 4.0L Unlocked Smartphone -US GSM -...        BLU   51.99   \n",
       "4  Huawei P8 Lite US Version- 5 Unlocked Android ...     Huawei  198.99   \n",
       "\n",
       "   Rating                                            Reviews  Review Votes  \n",
       "0       4             I love it!!! I absolutely love it!! üëåüëç           0.0  \n",
       "1       5  I love the BLU phones! This is my second one t...           4.0  \n",
       "2       5                                        Great phone           1.0  \n",
       "3       4  Very happy with the performance. The apps work...           2.0  \n",
       "4       5                            Easy to use great price           0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN = pd.read_csv(\"http://www.i3s.unice.fr/~riveill/dataset/Amazon_Unlocked_Mobile/train.csv.gz\")\n",
    "TEST = pd.read_csv(\"http://www.i3s.unice.fr/~riveill/dataset/Amazon_Unlocked_Mobile/test.csv.gz\")\n",
    "\n",
    "TRAIN.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build X (features vectors) and y (labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct X_train and y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T09:03:27.543378Z",
     "start_time": "2020-12-03T09:03:27.539586Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000,), (5000,))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = TRAIN['Reviews']\n",
    "y_train = TRAIN['Rating']\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Construct X_test and y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T14:19:54.481613Z",
     "start_time": "2020-12-01T14:19:54.478768Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000,), (1000,))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = TEST['Reviews']\n",
    "y_test = TEST['Rating']\n",
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct a Baseline\n",
    "Using a binary `CountVectorizer` and a `LogisticRegression` classifier, learned in a previous lecture, build a first model.\n",
    "\n",
    "For this model, you will not pre-process the text and will only use words (not N-grams). Leaves all parameter as default.\n",
    "\n",
    "The evaluation metric is accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T14:19:55.425571Z",
     "start_time": "2020-12-01T14:19:54.483899Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 8991)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Encode X_train '''\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer()\n",
    "cv.fit(X_train)\n",
    "X_train_encoded = cv.transform(X_train)\n",
    "X_train_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T14:19:55.427121Z",
     "start_time": "2020-12-01T14:19:53.484Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 8991)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Encode X_test '''\n",
    "X_test_encoded = cv.transform(X_test)\n",
    "X_test_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T14:19:55.428155Z",
     "start_time": "2020-12-01T14:19:53.598Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qlr/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Fit a model with train '''\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_encoded, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T14:19:55.429062Z",
     "start_time": "2020-12-01T14:19:53.774Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.666"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Evaluate a model with test '''\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = lr.predict(X_test_encoded)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A better classifier with a preprocessing\n",
    "\n",
    "It's up to you. Try to get a better score (accuracy) using what we have seen in this course:\n",
    "- efficient text pre-processing\n",
    "- choice of feature extraction\n",
    "- use of a more powerful classifier or better hyper-parameter for LogisticRegression.\n",
    "\n",
    "The training of the model must be done on the Train and the evaluation on the Test. You can of course use GridSearchCV or RandomizedSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T14:11:23.530114Z",
     "start_time": "2020-12-01T14:11:23.247542Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "# remove stop word (https://en.wikipedia.org/wiki/Stop_word)\n",
    "stop_word_list = [\".\", \",\", \"[\", \"]\", \"`\", \"(\", \")\", \"?\", \"'\", \"'s\", \":\", \"!\"]\n",
    "\n",
    "def remove_stop_word(txt_token, stop_word_list):\n",
    "    return [w for w in txt_token if w not in stop_word_list]\n",
    "\n",
    "def stemming(txt_token):\n",
    "    porter = nltk.PorterStemmer()\n",
    "    return [porter.stem(w) for w in txt_token]\n",
    "\n",
    "def lemmatization(txt_token):\n",
    "    WNlemma = nltk.WordNetLemmatizer()\n",
    "    return [WNlemma.lemmatize(w) for w in txt_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sentences = [lemmatization(stemming(remove_stop_word(word_tokenize(sentence), \n",
    "                                                               stop_word_list)))\n",
    "                       for sentence in X_train.append(X_test)]\n",
    "tokenized_sentences = list(map(\" \".join, tokenized_sentences))\n",
    "\n",
    "X_train_tokenized = tokenized_sentences[:5000]\n",
    "X_test_tokenized = tokenized_sentences[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qlr/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:497: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n",
      "  warnings.warn(\"The parameter 'stop_words' will not be used\"\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(analyzer=\"char_wb\", ngram_range=(1,4), stop_words=\"english\")\n",
    "cv.fit(X_train_tokenized)\n",
    "X_train_encoded = cv.transform(X_train_tokenized)\n",
    "X_test_encoded = cv.transform(X_test_tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing different hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.647"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(penalty=\"l2\", solver=\"newton-cg\", max_iter=100)\n",
    "lr.fit(X_train_encoded, y_train)\n",
    "y_pred = lr.predict(X_test_encoded)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.647"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(solver=\"newton-cg\", max_iter=1000)\n",
    "lr.fit(X_train_encoded, y_train)\n",
    "y_pred = lr.predict(X_test_encoded)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qlr/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.671"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_encoded, y_train)\n",
    "y_pred = lr.predict(X_test_encoded)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qlr/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.637"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train_encoded, y_train)\n",
    "y_pred = lr.predict(X_test_encoded)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.644"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(solver=\"liblinear\")\n",
    "lr.fit(X_train_encoded, y_train)\n",
    "y_pred = lr.predict(X_test_encoded)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize your conclusion here\n",
    "\n",
    "Give the best score obtained and describe the pipeline that allows you to obtain it."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The best score obtained with a logistic regression was an accuracy score of 0.671, barely above the logistic regression baseline without text preprocessing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
