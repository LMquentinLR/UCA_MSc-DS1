{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COURSE 1 - Statistical Inference 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*October, 16th, 2020*\n",
    "\n",
    "**Teacher**: Marco Corneli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark**: Most Theoretical Courses will be covered in Statistical Inference 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Structure of Class\n",
    "\n",
    "0. <u>Recommended reading:</u> Larry Wasserman's \"All of Statistics, a Concise Course in Statistical Inference\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1\n",
    "*Covers Chapter 6 of All of Statistics*\n",
    "<hr>\n",
    "\n",
    "### Assumptions for the class\n",
    "1. We have a set of independent and indentically distributed random variables $X_1, ..., X_n$. An experiment is repeated $N$ times.\n",
    "2. There is a parametric model for $X_1, ..., X_n$ such that $X_1 \\sim f(x,\\mu,\\sigma^2)$ a probability density function (**pdf**) such that $f \\in CALIGRAPHIC F = \\{f(x,\\mu,\\sigma^2)=\\frac{1}{\\sqrt{2.\\pi\\sigma}}.e^{-\\frac{1}{2}.(\\frac{X-\\mu}{\\sigma})^2} | \\mu \\in \\mathbb{R}, \\sigma > 0\\}$\n",
    "3. The problem we face is the estimation of $\\mu$ and $\\sigma$.\n",
    "4. $P_{\\mu,\\sigma}\\{X_1 \\le x\\} = F_{\\mu,\\sigma}(x)$ with $F$ the cumulative distribution function (**cdf**)\n",
    "\n",
    "> Often , when x_1 is a continuous random variable \n",
    "> \n",
    "> $F(x)=\\int_{-\\infty}^{x}f(x,\\theta)dx$ with f(.,\\theta) is the PDF of $X_i$ and $\\theta$ some parameter.\n",
    "\n",
    "5. For <u>non-parametric models</u>, we know that $X_1, ..., X_n$ i.i.d. follows a certain CDF F w/ F unknown, and we always assume that $F\\in Caligraphic F = \\{all CDFs\\}$. Example:\n",
    "> $X_1, ..., X_n$ are coin flips, $X_1 \\~ Ber(p)$\n",
    ">\n",
    "> if $X_1 \\~ Ber(p) \\Rightarrow P_p(X=1)=p$, $P_p(X=0)=1-p$ and $\\mu=p$, $\\sigma=p.(1-p)$\n",
    ">\n",
    "> The question would be \"How to estimate p\"?\n",
    "\n",
    "<hr>\n",
    "<u>Example of gaussian model:</u>\n",
    "\n",
    "$P(X\\le x)=F(x)=\\int_{-\\infty}^{x}\\frac{1}{\\sqrt{2.\\pi\\sigma}}.e^{-\\frac{1}{2}.(\\frac{X-\\mu}{\\sigma})^2}dx$\n",
    "\n",
    "<hr>\n",
    "<u>Example of regression:</u>\n",
    "You observe $(X_1,y_1),...,ADD3\n",
    "NOTE1\n",
    "We want to focus on the value $R(x) = \\mathbb{E}(y_i|X_i=x) \\leftarrow$ quantity to model ($\\ast$)\n",
    "\n",
    "**observation**: Given the observation ($\\ast$), $y_i = y_i+R(X_i)-R(X_i) = R(X_i) + y_i-R(X_i) = R(X_i) + \\epsilon_i$ and:\n",
    "\n",
    "> $\\mathbb{E}[\\epsilon_i]=\\mathbb{E}[\\mathbb{E}[\\epsilon_i|X_i]] = \\mathbb{E}[\\mathbb{E}[y_i-R(X_i)|X_i]]=\\mathbb{E}[\\mathbb{E}[y_i|X_i]-R(X_i)]=0$ \n",
    "> \n",
    "> with $\\mathbb{E}[y_i|X_i]=R(X_i)$ \n",
    "\n",
    "What about R(x)?\n",
    "- ADD5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point Estimation\n",
    "\n",
    "In all cases, we saw there is a parameter $\\theta$ to estimate. An estimator **$\\hat{\\theta_n}$** is a random variable (depends on the data).\n",
    "\n",
    "> $\\hat{\\theta_n}:=g(X_1,...,X_n)$\n",
    "<hr>\n",
    "<u>Example of linear multivariate regression:</u>\n",
    "\n",
    "$y=X.\\beta+\\epsilon \\Rightarrow y_i=\\beta_0+\\beta_1.x_{i,1}+...+\\beta_n.x^{i,n}$ with $[X]_{i,j} = x_{i,j}$ and $\\hat{\\beta_{ols}}=(X^T.X)^{-1}X^T.y$ (OLS: ordinary least square)\n",
    "\n",
    "<u>Example of coin toss:</u>\n",
    "\n",
    "$X_1,...,X_n\\sim Ber(p) \\Rightarrow \\hat{p}=\\frac{1}{N}\\sum_{i=1}^NX_i = \\bar{X}$ sample mean\n",
    "\n",
    "Here $g(X_1,...,X_n)=\\frac{1}{N}\\sum_{i=1}^NX_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is the estimator $\\hat{\\theta_n}$ an unbiased estimator of $\\theta$?\n",
    "\n",
    "<u>*Meaning*:</u> it means $bias(\\hat{\\theta_n})=\\mathbb{E}(\\hat{\\theta_n})-\\theta$. If $bias(\\hat{\\theta_n})=0$ it means $\\hat{\\theta_n}$ is unbiased.\n",
    "<hr>\n",
    "<u>Example of coin toss:</u> Is $\\hat{p}=\\frac{1}{N}\\sum_{i=1}^NX_i$ unbiased?\n",
    "\n",
    "$\\mathbb{E}_p[\\hat{p}]=\\mathbb{E}_p[\\frac{1}{N}\\sum_{i=1}^NX_i] \\\\= \\frac{1}{N}\\sum_{i=1}^N\\mathbb{E}_p[X_i] = \\frac{1}{N}\\sum_{i=1}^Np=\\frac{N.p}{N}=p$\n",
    "\n",
    "$bias(\\hat{\\theta_n})=\\mathbb{E}_p[\\hat{p}]-p=p-p=0$ \n",
    "\n",
    "It is unbiased.\n",
    "<hr>\n",
    "\n",
    "<u>**definition**:</u> $\\hat{\\theta_n}$ is a consistent (synonymous with convergent) estimator of $\\theta$ if ADD 6\n",
    "\n",
    "<u>**theorem**:</u> if $\\hat{\\theta_n}$ is unbiased and ADD7\n",
    "\n",
    "<u>**proof**:</u> ADD8-9\n",
    "\n",
    "<u>**Note** on Markhov's Inequality:</u>\n",
    "\n",
    "<u>Example:</u>\n",
    "\n",
    "$X_1,...,X_N\\underset{iid}{\\sim}Ber(p)$, $\\hat{p_N}=\\frac{1}{N}\\sum_{i=1}^{N}X_i$, with:\n",
    "\n",
    "$E_p[\\hat{p_N}]=P(bias(\\hat{p_N})=0)$\n",
    "\n",
    "$Var_p(\\hat{p_N})=Var_p(\\frac{1}{N}\\sum_{i=1}^{N}X_i)$\n",
    "\n",
    "*Recall*: Usually $Var(X+Y)\\neq Var(X)+Var(Y)$ except when $X \\perp Y$ \n",
    "\n",
    "Then $X$ and $Y$ are independent $\\Rightarrow Var(X+Y)=Var(X)+Var(Y)$\n",
    "\n",
    "Thus: $Var_p(\\hat{p_N})=\\frac{1}{N^2}.\\sum_{i=1}^{N}Var_p(X_i)=\\frac{1}{N^2}.N.p.(1-p)\\\\ \\Rightarrow Var_p(\\hat{p_N})=\\frac{p.(1-p)}{N}$\n",
    "\n",
    "$Var_p(\\hat{p_N})$ converges in probability towards $\\theta$ when N goes towards $+\\infty$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO \n",
    "# EXERCISE 1,2,3 p95-96"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
